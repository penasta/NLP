{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Talvez fosse mais eficiente trabalhar com o Polars, porém não consigo instalá-lo na máquina do STF...\n",
    "import nltk # Pacote para remoção de stopwords em português\n",
    "import unidecode \n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dados.csv')\n",
    "corpus = []\n",
    "for i in range(0,dataset.shape[0]): # Este index irá funcionar somente se a coluna texto for a primeira (índice 0). Deve-se alterar, c.c.\n",
    "    texto = re.sub('[^a-zA-Z]',' ',unidecode.unidecode(dataset['texto'][i]) )\n",
    "    texto = texto.lower()\n",
    "    texto = texto.split() #convert into list\n",
    "    ps = PorterStemmer()\n",
    "    texto = [ps.stem(word) for word in texto if not word in set(stopwords.words('portuguese'))]\n",
    "    texto = ' '.join(texto)\n",
    "    corpus.append(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW\n",
    "cv=CountVectorizer(max_features = 5000)\n",
    "X=cv.fit_transform(corpus).toarray()\n",
    "y=dataset.iloc[:,1].values # Coluna do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[495, 139],\n",
       "       [209, 332]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting classifier to the Training set\n",
    "model_RF=RandomForestClassifier(n_estimators =400,criterion=\"entropy\",random_state =0)\n",
    "model_RF.fit(X_train,y_train)\n",
    "y_pred_RF = model_RF.predict(X_test)\n",
    "cm1 = confusion_matrix(y_test, y_pred_RF)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[454, 180],\n",
       "       [219, 322]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_XGB = XGBClassifier(n_estimators=400, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "model_XGB.fit(X_train, y_train)\n",
    "y_pred_XGB = model_XGB.predict(X_test)\n",
    "cm2 = confusion_matrix(y_test, y_pred_XGB)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6779021\ttotal: 17.4ms\tremaining: 34.8ms\n",
      "1:\tlearn: 0.6681406\ttotal: 32.9ms\tremaining: 16.5ms\n",
      "2:\tlearn: 0.6608500\ttotal: 49.3ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[618,  16],\n",
       "       [509,  32]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CB = CatBoostClassifier(iterations=3,\n",
    "                           depth=3,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "model_CB.fit(X_train, y_train)\n",
    "y_pred_CB = model_CB.predict(X_test)\n",
    "cm3 = confusion_matrix(y_test, y_pred_CB)\n",
    "cm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[588,  46],\n",
       "       [379, 162]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbc = GradientBoostingClassifier()\n",
    "model_gbc.fit(X_train, y_train)\n",
    "y_pred_gbc = model_gbc.predict(X_test)\n",
    "cm4 = confusion_matrix(y_test, y_pred_gbc)\n",
    "cm4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[593,  41],\n",
       "       [425, 116]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = svm.SVC()\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "cm5 = confusion_matrix(y_test, y_pred_svm)\n",
    "cm5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[217, 417],\n",
       "       [ 79, 462]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GNB = GaussianNB()\n",
    "model_GNB.fit(X_train, y_train)\n",
    "y_pred_GNB = model_GNB.predict(X_test)\n",
    "cm6 = confusion_matrix(y_test, y_pred_GNB)\n",
    "cm6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[462, 172],\n",
       "       [221, 320]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MNB = MultinomialNB()\n",
    "model_MNB.fit(X_train, y_train)\n",
    "y_pred_MNB = model_MNB.predict(X_test)\n",
    "cm7 = confusion_matrix(y_test, y_pred_MNB)\n",
    "cm7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[462, 172],\n",
       "       [221, 320]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNB = MultinomialNB()\n",
    "model_CNB.fit(X_train, y_train)\n",
    "y_pred_CNB = model_CNB.predict(X_test)\n",
    "cm8 = confusion_matrix(y_test, y_pred_CNB)\n",
    "cm8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montando a função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP(dataset): # Input: Dataset inteiro: 2 colunas: texto + rótulo\n",
    "\n",
    "    # Bloco 1: Processamento do texto\n",
    "\n",
    "    corpus = []\n",
    "    for i in range(0,dataset.shape[0]): # Este index irá funcionar somente se a coluna texto for a primeira (índice 0). Deve-se alterar, c.c.\n",
    "        texto = re.sub('[^a-zA-Z]',' ',unidecode.unidecode(dataset['texto'][i]) )\n",
    "        texto = texto.lower()\n",
    "        texto = texto.split() #convert into list\n",
    "        ps = PorterStemmer()\n",
    "        texto = [ps.stem(word) for word in texto if not word in set(stopwords.words('portuguese'))]\n",
    "        texto = ' '.join(texto)\n",
    "        corpus.append(texto)\n",
    "\n",
    "    # Bloco 2: Embedding do texto\n",
    "\n",
    "    # BoW\n",
    "    cv=CountVectorizer(max_features = 5000)\n",
    "    X=cv.fit_transform(corpus).toarray()\n",
    "    y=dataset.iloc[:,1].values # Coluna do classificador\n",
    "\n",
    "    # Bloco 3 : Algorítmos de NLP\n",
    "\n",
    "    # Random forest\n",
    "    model_RF=RandomForestClassifier(n_estimators =400,criterion=\"entropy\",random_state =0)\n",
    "    model_RF.fit(X_train,y_train)\n",
    "\n",
    "    # XGBoost:\n",
    "    model_XGB = XGBClassifier(n_estimators=400, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "    model_XGB.fit(X_train, y_train)\n",
    "\n",
    "    # Catboost:\n",
    "    model_CB = CatBoostClassifier(iterations=3,\n",
    "                           depth=3,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "    model_CB.fit(X_train, y_train)\n",
    "\n",
    "    # Gradient Boosting Classifier:\n",
    "    model_GBC = GradientBoostingClassifier()\n",
    "    model_GBC.fit(X_train, y_train)\n",
    "\n",
    "    # SVM:\n",
    "    model_SVM = svm.SVC()\n",
    "    model_SVM.fit(X_train, y_train)\n",
    "\n",
    "    # Naive Bayes Gaussian:\n",
    "    model_GNB = GaussianNB()\n",
    "    model_GNB.fit(X_train, y_train)\n",
    "\n",
    "    # Naive Bayes Multinomial:\n",
    "    model_MNB = MultinomialNB()\n",
    "    model_MNB.fit(X_train, y_train)\n",
    "\n",
    "    # Naive Bayes Complement:\n",
    "    model_CNB = MultinomialNB()\n",
    "    model_CNB.fit(X_train, y_train)\n",
    "\n",
    "    # Bloco 4: Acumulador/organizador de resultados\n",
    "\n",
    "    # Random Forest:\n",
    "    y_pred_RF = model_RF.predict(X_test)\n",
    "    cm1 = confusion_matrix(y_test, y_pred_RF)\n",
    "\n",
    "    # XGBoost:\n",
    "    y_pred_XGB = model_XGB.predict(X_test)\n",
    "    cm2 = confusion_matrix(y_test, y_pred_XGB)\n",
    "\n",
    "    # Catboost:\n",
    "    y_pred_CB = model_CB.predict(X_test)\n",
    "    cm3 = confusion_matrix(y_test, y_pred_CB)\n",
    "\n",
    "    # Gradient Boosting Classifier:\n",
    "    y_pred_gbc = model_GBC.predict(X_test)\n",
    "    cm4 = confusion_matrix(y_test, y_pred_gbc)\n",
    "\n",
    "    # SVM:\n",
    "    y_pred_svm = model_SVM.predict(X_test)\n",
    "    cm5 = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "    # Naive Bayes Gaussian:\n",
    "    y_pred_GNB = model_GNB.predict(X_test)\n",
    "    cm6 = confusion_matrix(y_test, y_pred_GNB)\n",
    "\n",
    "    # Naive Bayes Multinomial:\n",
    "    y_pred_MNB = model_MNB.predict(X_test)\n",
    "    cm7 = confusion_matrix(y_test, y_pred_MNB)\n",
    "\n",
    "    # Naive Bayes Complement:\n",
    "    y_pred_CNB = model_CNB.predict(X_test)\n",
    "    cm8 = confusion_matrix(y_test, y_pred_CNB)\n",
    "\n",
    "    # Bloco 5: Saída\n",
    "    # Saída esperada: Acurária; F1-Score e Precisão de cada algoritmo\n",
    "\n",
    "    return cm1,cm2,cm3,cm4,cm5,cm6,cm7,cm8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6779021\ttotal: 15.8ms\tremaining: 31.6ms\n",
      "1:\tlearn: 0.6681406\ttotal: 31.1ms\tremaining: 15.6ms\n",
      "2:\tlearn: 0.6608500\ttotal: 46ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[495, 139],\n",
       "        [209, 332]], dtype=int64),\n",
       " array([[454, 180],\n",
       "        [219, 322]], dtype=int64),\n",
       " array([[618,  16],\n",
       "        [509,  32]], dtype=int64),\n",
       " array([[589,  45],\n",
       "        [378, 163]], dtype=int64),\n",
       " array([[593,  41],\n",
       "        [425, 116]], dtype=int64),\n",
       " array([[217, 417],\n",
       "        [ 79, 462]], dtype=int64),\n",
       " array([[462, 172],\n",
       "        [221, 320]], dtype=int64),\n",
       " array([[462, 172],\n",
       "        [221, 320]], dtype=int64))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
