{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função NLP\n",
    "## Versão 1.1.1 \n",
    "### Versão Python utilizada: Python 3.11.3 (Anaconda) | IDE: VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import unidecode \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP(dataset,algoritmo): # Input: Dataset inteiro: 2 colunas: texto + rótulo ; qual algoritmo usar\n",
    "\n",
    "    # Bloco 1: Processamento do texto\n",
    "\n",
    "    corpus = []\n",
    "    for i in range(0,dataset.shape[0]):\n",
    "        texto = re.sub('[^a-zA-Z]',' ',unidecode.unidecode(dataset['texto'][i]) )\n",
    "        texto = texto.lower()\n",
    "        texto = texto.split()\n",
    "        ps = PorterStemmer()\n",
    "        texto = [ps.stem(word) for word in texto if not word in set(stopwords.words('portuguese'))]\n",
    "        texto = ' '.join(texto)\n",
    "        corpus.append(texto)\n",
    "\n",
    "    # Bloco 2: Embedding do texto\n",
    "\n",
    "    # BoW\n",
    "    cv=CountVectorizer(max_features = 5000)\n",
    "    X=cv.fit_transform(corpus).toarray()\n",
    "    y=dataset.iloc[:,1].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "    # Bloco 3 : Algorítmos de NLP\n",
    "    metricas = {}\n",
    "\n",
    "    if algoritmo == \"rf\":\n",
    "\n",
    "    # Random forest\n",
    "        model_RF=RandomForestClassifier(n_estimators = 400,criterion=\"entropy\",random_state = 0)\n",
    "        model_RF.fit(X_train,y_train)\n",
    "\n",
    "        y_pred_RF = model_RF.predict(X_test)\n",
    "        metricas[\"Random Forest\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_RF),\n",
    "            \"precisão\": precision_score(y_test, y_pred_RF),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_RF)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "\n",
    "    elif algoritmo == \"xg\":\n",
    "\n",
    "    # XGBoost\n",
    "        model_XGB = XGBClassifier(n_estimators = 400, max_depth = 2, learning_rate = 1, objective = 'binary:logistic')\n",
    "        model_XGB.fit(X_train, y_train)\n",
    "        y_pred_XGB = model_XGB.predict(X_test)\n",
    "        metricas[\"XGBoost\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_XGB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_XGB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_XGB)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "    elif algoritmo == \"cb\":\n",
    "\n",
    "    # Catboost:\n",
    "        model_CB = CatBoostClassifier(iterations = 3,\n",
    "                            depth = 3,\n",
    "                            learning_rate = 1,\n",
    "                            loss_function = 'Logloss',\n",
    "                            verbose = False)\n",
    "        model_CB.fit(X_train, y_train)\n",
    "        y_pred_CB = model_CB.predict(X_test)\n",
    "        metricas[\"Catboost\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_CB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_CB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_CB)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "\n",
    "\n",
    "\n",
    "    elif algoritmo == \"gbc\":\n",
    "\n",
    "    # Gradient Boosting Classifier:\n",
    "        model_GBC = GradientBoostingClassifier()\n",
    "        model_GBC.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_gbc = model_GBC.predict(X_test)\n",
    "        metricas[\"Gradient Boosting Classifier\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_gbc),\n",
    "            \"precisão\": precision_score(y_test, y_pred_gbc),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_gbc)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "\n",
    "    elif algoritmo == \"svm\":\n",
    "\n",
    "    # SVM:\n",
    "        model_SVM = svm.SVC()\n",
    "        model_SVM.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_svm = model_SVM.predict(X_test)\n",
    "        metricas[\"SVM\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_svm),\n",
    "            \"precisão\": precision_score(y_test, y_pred_svm),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_svm)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "\n",
    "    elif algoritmo == \"gnb\":\n",
    "\n",
    "    # Naive Bayes Gaussian:\n",
    "        model_GNB = GaussianNB()\n",
    "        model_GNB.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_GNB = model_GNB.predict(X_test)\n",
    "        metricas[\"Naive Bayes Gaussian\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_GNB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_GNB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_GNB)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "\n",
    "    elif algoritmo == \"mnb\":\n",
    "\n",
    "    # Naive Bayes Multinomial:\n",
    "        model_MNB = MultinomialNB()\n",
    "        model_MNB.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_MNB = model_MNB.predict(X_test)\n",
    "        metricas[\"Naive Bayes Multinomial\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_MNB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_MNB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_MNB)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "\n",
    "    elif algoritmo == \"cnb\":\n",
    "\n",
    "    # Naive Bayes Complement:\n",
    "        model_CNB = ComplementNB()\n",
    "        model_CNB.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_CNB = model_CNB.predict(X_test)\n",
    "        metricas[\"Naive Bayes Complement\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_CNB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_CNB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_CNB)\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(metricas)\n",
    "        df = df.transpose()\n",
    "        print(df)\n",
    "\n",
    "    else:\n",
    "        model_RF = RandomForestClassifier(n_estimators = 400,criterion = \"entropy\",random_state = 0)\n",
    "        model_RF.fit(X_train,y_train)     \n",
    "        model_XGB = XGBClassifier(n_estimators = 400, max_depth = 2, learning_rate = 1, objective = 'binary:logistic')\n",
    "        model_XGB.fit(X_train, y_train)\n",
    "        model_CB = CatBoostClassifier(iterations = 3,\n",
    "                            depth = 3,\n",
    "                            learning_rate = 1,\n",
    "                            loss_function = 'Logloss',\n",
    "                            verbose = False)\n",
    "        model_CB.fit(X_train, y_train)\n",
    "        model_GBC = GradientBoostingClassifier()\n",
    "        model_GBC.fit(X_train, y_train)\n",
    "        model_SVM = svm.SVC()\n",
    "        model_SVM.fit(X_train, y_train)\n",
    "        model_GNB = GaussianNB()\n",
    "        model_GNB.fit(X_train, y_train)\n",
    "        model_MNB = MultinomialNB()\n",
    "        model_MNB.fit(X_train, y_train)\n",
    "        model_CNB = ComplementNB()\n",
    "        model_CNB.fit(X_train, y_train)\n",
    "\n",
    "        # Bloco 4: Acumulador/organizador de resultados\n",
    "        metricas = {}\n",
    "\n",
    "        # Random Forest:\n",
    "        y_pred_RF = model_RF.predict(X_test)\n",
    "        metricas[\"Random Forest\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_RF),\n",
    "            \"precisão\": precision_score(y_test, y_pred_RF),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_RF)\n",
    "        }\n",
    "\n",
    "        # XGBoost:\n",
    "        y_pred_XGB = model_XGB.predict(X_test)\n",
    "        metricas[\"XGBoost\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_XGB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_XGB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_XGB)\n",
    "        }\n",
    "\n",
    "        # Catboost:\n",
    "        y_pred_CB = model_CB.predict(X_test)\n",
    "        metricas[\"Catboost\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_CB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_CB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_CB)\n",
    "        }\n",
    "\n",
    "        # Gradient Boosting Classifier:\n",
    "        y_pred_gbc = model_GBC.predict(X_test)\n",
    "        metricas[\"Gradient Boosting Classifier\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_gbc),\n",
    "            \"precisão\": precision_score(y_test, y_pred_gbc),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_gbc)\n",
    "        }\n",
    "\n",
    "        # SVM:\n",
    "        y_pred_svm = model_SVM.predict(X_test)\n",
    "        metricas[\"SVM\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_svm),\n",
    "            \"precisão\": precision_score(y_test, y_pred_svm),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_svm)\n",
    "        }\n",
    "\n",
    "        # Naive Bayes Gaussian:\n",
    "        y_pred_GNB = model_GNB.predict(X_test)\n",
    "        metricas[\"Naive Bayes Gaussian\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_GNB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_GNB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_GNB)\n",
    "        }\n",
    "\n",
    "        # Naive Bayes Multinomial:\n",
    "        y_pred_MNB = model_MNB.predict(X_test)\n",
    "        metricas[\"Naive Bayes Multinomial\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_MNB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_MNB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_MNB)\n",
    "        }\n",
    "\n",
    "        # Naive Bayes Complement:\n",
    "        y_pred_CNB = model_CNB.predict(X_test)\n",
    "        metricas[\"Naive Bayes Complement\"] = {\n",
    "            \"acurácia\": accuracy_score(y_test, y_pred_CNB),\n",
    "            \"precisão\": precision_score(y_test, y_pred_CNB),\n",
    "            \"f1 score\": f1_score(y_test, y_pred_CNB)\n",
    "        }\n",
    "\n",
    "        # Bloco 5: Saída\n",
    "        # Crie o DataFrame a partir do dicionário de métricas\n",
    "        df = pd.DataFrame(metricas)\n",
    "\n",
    "        # Transponha o DataFrame para que os nomes dos algoritmos sejam nas linhas e as métricas nas colunas\n",
    "        df = df.transpose()\n",
    "\n",
    "        # Imprima o DataFrame como uma tabela\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               acurácia  f1 score  precisão\n",
      "Random Forest   0.70383  0.656126  0.704883\n"
     ]
    }
   ],
   "source": [
    "NLP(dataset,algoritmo=\"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          acurácia  f1 score  precisão\n",
      "Catboost  0.553191  0.108659  0.666667\n"
     ]
    }
   ],
   "source": [
    "NLP(dataset,algoritmo=\"cb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              acurácia  precisão  f1 score\n",
      "Random Forest                 0.703830  0.704883  0.656126\n",
      "XGBoost                       0.660426  0.641434  0.617450\n",
      "Catboost                      0.553191  0.666667  0.108659\n",
      "Gradient Boosting Classifier  0.640000  0.783654  0.435247\n",
      "SVM                           0.603404  0.738854  0.332378\n",
      "Naive Bayes Gaussian          0.577872  0.525597  0.650704\n",
      "Naive Bayes Multinomial       0.665532  0.650407  0.619555\n",
      "Naive Bayes Complement        0.667234  0.629758  0.650581\n"
     ]
    }
   ],
   "source": [
    "NLP(dataset=dataset,algoritmo=\"todos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
