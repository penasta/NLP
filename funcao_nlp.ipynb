{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função NLP\n",
    "## Versão 1.0.0 \n",
    "### Versão Python utilizada: Python 3.11.3 (Anaconda) | IDE: VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import unidecode \n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP(dataset,algoritmo): # Input: Dataset inteiro: 2 colunas: texto + rótulo ; qual algoritmo usar\n",
    "\n",
    "    # Bloco 1: Processamento do texto\n",
    "\n",
    "    corpus = []\n",
    "    for i in range(0,dataset.shape[0]):\n",
    "        texto = re.sub('[^a-zA-Z]',' ',unidecode.unidecode(dataset['texto'][i]) )\n",
    "        texto = texto.lower()\n",
    "        texto = texto.split()\n",
    "        ps = PorterStemmer()\n",
    "        texto = [ps.stem(word) for word in texto if not word in set(stopwords.words('portuguese'))]\n",
    "        texto = ' '.join(texto)\n",
    "        corpus.append(texto)\n",
    "\n",
    "    # Bloco 2: Embedding do texto\n",
    "\n",
    "    # BoW\n",
    "    cv=CountVectorizer(max_features = 5000)\n",
    "    X=cv.fit_transform(corpus).toarray()\n",
    "    y=dataset.iloc[:,1].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "    # Bloco 3 : Algorítmos de NLP\n",
    "\n",
    "    if algoritmo == \"rf\":\n",
    "\n",
    "    # Random forest\n",
    "        model_RF=RandomForestClassifier(n_estimators =400,criterion=\"entropy\",random_state =0)\n",
    "        model_RF.fit(X_train,y_train)\n",
    "\n",
    "        y_pred_RF = model_RF.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_RF))\n",
    "\n",
    "    elif algoritmo == \"xgb\":\n",
    "\n",
    "    # XGBoost:\n",
    "        model_XGB = XGBClassifier(n_estimators=400, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "        model_XGB.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_XGB = model_XGB.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_XGB))\n",
    "\n",
    "    elif algoritmo == \"cb\":\n",
    "\n",
    "    # Catboost:\n",
    "        model_CB = CatBoostClassifier(iterations=3,\n",
    "                            depth=3,\n",
    "                            learning_rate=1,\n",
    "                            loss_function='Logloss',\n",
    "                            verbose=True)\n",
    "        model_CB.fit(X_train, y_train)\n",
    "        y_pred_CB = model_CB.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_CB))\n",
    "\n",
    "    elif algoritmo == \"gbc\":\n",
    "\n",
    "    # Gradient Boosting Classifier:\n",
    "        model_GBC = GradientBoostingClassifier()\n",
    "        model_GBC.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_gbc = model_GBC.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_gbc))\n",
    "\n",
    "    elif algoritmo == \"svm\":\n",
    "\n",
    "    # SVM:\n",
    "        model_SVM = svm.SVC()\n",
    "        model_SVM.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_svm = model_SVM.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "    elif algoritmo == \"gnb\":\n",
    "\n",
    "    # Naive Bayes Gaussian:\n",
    "        model_GNB = GaussianNB()\n",
    "        model_GNB.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_GNB = model_GNB.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_GNB))\n",
    "\n",
    "    elif algoritmo == \"mnb\":\n",
    "\n",
    "    # Naive Bayes Multinomial:\n",
    "        model_MNB = MultinomialNB()\n",
    "        model_MNB.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_MNB = model_MNB.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_MNB))\n",
    "\n",
    "    elif algoritmo == \"cnb\":\n",
    "\n",
    "    # Naive Bayes Complement:\n",
    "        model_CNB = MultinomialNB()\n",
    "        model_CNB.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_CNB = model_CNB.predict(X_test)\n",
    "        return(confusion_matrix(y_test, y_pred_CNB))\n",
    "\n",
    "    else:\n",
    "        model_RF=RandomForestClassifier(n_estimators =400,criterion=\"entropy\",random_state =0)\n",
    "        model_RF.fit(X_train,y_train)     \n",
    "        model_XGB = XGBClassifier(n_estimators=400, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "        model_XGB.fit(X_train, y_train)\n",
    "        model_CB = CatBoostClassifier(iterations=3,\n",
    "                            depth=3,\n",
    "                            learning_rate=1,\n",
    "                            loss_function='Logloss',\n",
    "                            verbose=True)\n",
    "        model_CB.fit(X_train, y_train)\n",
    "        model_GBC = GradientBoostingClassifier()\n",
    "        model_GBC.fit(X_train, y_train)\n",
    "        model_SVM = svm.SVC()\n",
    "        model_SVM.fit(X_train, y_train)\n",
    "        model_GNB = GaussianNB()\n",
    "        model_GNB.fit(X_train, y_train)\n",
    "        model_MNB = MultinomialNB()\n",
    "        model_MNB.fit(X_train, y_train)\n",
    "        model_CNB = MultinomialNB()\n",
    "        model_CNB.fit(X_train, y_train)\n",
    "\n",
    "        # Bloco 4: Acumulador/organizador de resultados\n",
    "\n",
    "        # Random Forest:\n",
    "        y_pred_RF = model_RF.predict(X_test)\n",
    "        cm1 = confusion_matrix(y_test, y_pred_RF)\n",
    "\n",
    "        # XGBoost:\n",
    "        y_pred_XGB = model_XGB.predict(X_test)\n",
    "        cm2 = confusion_matrix(y_test, y_pred_XGB)\n",
    "\n",
    "        # Catboost:\n",
    "        y_pred_CB = model_CB.predict(X_test)\n",
    "        cm3 = confusion_matrix(y_test, y_pred_CB)\n",
    "\n",
    "        # Gradient Boosting Classifier:\n",
    "        y_pred_gbc = model_GBC.predict(X_test)\n",
    "        cm4 = confusion_matrix(y_test, y_pred_gbc)\n",
    "\n",
    "        # SVM:\n",
    "        y_pred_svm = model_SVM.predict(X_test)\n",
    "        cm5 = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "        # Naive Bayes Gaussian:\n",
    "        y_pred_GNB = model_GNB.predict(X_test)\n",
    "        cm6 = confusion_matrix(y_test, y_pred_GNB)\n",
    "\n",
    "        # Naive Bayes Multinomial:\n",
    "        y_pred_MNB = model_MNB.predict(X_test)\n",
    "        cm7 = confusion_matrix(y_test, y_pred_MNB)\n",
    "\n",
    "        # Naive Bayes Complement:\n",
    "        y_pred_CNB = model_CNB.predict(X_test)\n",
    "        cm8 = confusion_matrix(y_test, y_pred_CNB)\n",
    "\n",
    "        # Bloco 5: Saída\n",
    "        # Saída esperada: Acurária; F1-Score e Precisão de cada algoritmo | Acabei optanto pela matriz de confusão por enquanto, pela simplicidade de implementação. Futuramente irei alterar para o output solicitado.\n",
    "        \n",
    "\n",
    "        return cm1,cm2,cm3,cm4,cm5,cm6,cm7,cm8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[495, 139],\n",
       "       [209, 332]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP(dataset,algoritmo=\"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6779021\ttotal: 178ms\tremaining: 356ms\n",
      "1:\tlearn: 0.6681406\ttotal: 192ms\tremaining: 96.2ms\n",
      "2:\tlearn: 0.6608500\ttotal: 206ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[495, 139],\n",
       "        [209, 332]], dtype=int64),\n",
       " array([[454, 180],\n",
       "        [219, 322]], dtype=int64),\n",
       " array([[618,  16],\n",
       "        [509,  32]], dtype=int64),\n",
       " array([[588,  46],\n",
       "        [379, 162]], dtype=int64),\n",
       " array([[593,  41],\n",
       "        [425, 116]], dtype=int64),\n",
       " array([[217, 417],\n",
       "        [ 79, 462]], dtype=int64),\n",
       " array([[462, 172],\n",
       "        [221, 320]], dtype=int64),\n",
       " array([[462, 172],\n",
       "        [221, 320]], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP(dataset=dataset,algoritmo=\"todos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
